# Session: 2026-02-10

**Focus:** M4 Architecture Design (Delegation Pattern)
**Duration:** ~2.5 hours (3:26 PM - 6:49 PM)

## Retention Check (Passed ✓)

Kartik demonstrated solid understanding of Session 1 concepts:
1. **Agent vs LLM** — loop, goal-directed, autonomy, observation
2. **ReAct** — reasoning for visibility, debuggability, metacognition ("knowing what it doesn't know")
3. **Tools** — description as contract, semantics matter, parameters clearly defined

## Session 2 Concepts Covered

### 1. Multi-Agent Patterns
- **Delegation:** Single sub-agent, fire-and-forget, no routing decision
- **Orchestration:** Multiple specialists, active routing based on task analysis
- **Debate/Critique:** Agents review each other's work

**Kartik's insight:** "Orchestration eventually leads to delegation once the main agent knows what's needed."

**Decision:** Start with delegation (simpler), evolve to orchestration later.

### 2. Trigger Design
- **Keyword matching:** Brittle, doesn't scale
- **Intent detection:** LLM reasons over query to classify intent
- **Ambiguity handling:** Ask for clarification

**Kartik's reasoning:** Clarification friction < wrong-output friction. Also enables better evals (ambiguous scenarios become testable).

**Connection to ReAct:** Clarification demonstrates "knowing what it doesn't know."

### 3. Handoff Design
- **Default:** Query + recent conversation summary
- **Triggered:** Memory files (only when user signals historical context needed)
- **User-specified:** Focus areas, constraints, output format

**Kartik's insight:** "Don't pull memory files by default — that involves reading, parsing, reasoning, injection. Unnecessary token usage."

**Principle:** Lazy context loading — default to cheapest context that's likely relevant.

### 4. Return Design
- Research agent returns: raw findings, sources, confidence, gaps, suggested followups
- Main agent handles: synthesis, formatting, user communication

**Kartik's key insight:** "Research agent is a researcher, not a presenter. It doesn't handle summarization — you handle that because you're communicating to the user."

**Principle:** Sub-agents return complete raw data. Main agent owns presentation.

### 5. Integration Design
- **Validation:** Main agent checks if output addresses query before presenting
- **Retry logic:** Re-delegate silently if insufficient (user implicitly authorized tokens)
- **Circuit breaker:** Max 3 attempts, then ask user
- **Memory:** User-triggered persistence, not automatic

### 6. LLM-as-Judge
- Validation is another LLM call (cheap, structured)
- Prompt asks: coverage? relevance? constraint compliance? confidence?
- Returns verdict: PASS / NEEDS_REFINEMENT / INSUFFICIENT
- Also returns refinement_hint for re-delegation

**Kartik's question:** "Is this how existing systems do validation?"
**Answer:** Yes, but also heuristics, embedding similarity, and hybrid approaches. Production often uses hybrid (cheap checks first, LLM-as-judge for borderline cases).

### 7. Research Agent Internals
- Core loop: Think → Act → Observe → Evaluate → (loop or return)
- Tools: web_search (minimum), browse_url (optional)
- Behavior encoded via system prompt
- Some behaviors enforced in code (max searches, timeout, output schema)

### 8. Research Agent Design Patterns
- **Iterative:** Search → observe → decide → search again (flexible, unpredictable)
- **Parallel:** Decompose upfront, search all at once (fast, rigid)
- **Hierarchical:** Plan → execute → review (thorough, slow)
- **Multi-agent:** Planner + researchers + critic + writer (modular, complex)

**Kartik analyzed Reddit diagram correctly:** Simple mode = iterative, Deep mode = parallel + hierarchical (plan phase, parallelized research, proofreader at end).

**Key insight:** "There's no standard — agent design is a tradeoff space."

## M4 Architecture Design (Complete)

| Component | Decision |
|-----------|----------|
| **Trigger** | Intent detection + clarification for ambiguity |
| **Handoff** | Query + conversation summary (default), memory/constraints (triggered) |
| **Return** | Raw findings + sources + confidence + gaps + followups |
| **Integration** | LLM-as-judge validation, retry logic, user-triggered memory |

## Concepts Locked This Session

1. [Multi-Agent Patterns](../concepts/multi-agent-patterns.md)
2. [Trigger Design](../concepts/trigger-design.md)
3. [Handoff Design](../concepts/handoff-design.md)
4. [Return Design](../concepts/return-design.md)
5. [Integration Design](../concepts/integration-design.md)
6. [LLM-as-Judge](../concepts/llm-as-judge.md)
7. [Research Agent Internals](../concepts/research-agent-internals.md)
8. [Research Agent Design Patterns](../concepts/research-agent-design-patterns.md)

## Questions That Emerged

**Answered this session:**
- How does validation work in implementation? (LLM-as-judge)
- Is there a standard way to design research agents? (No — tradeoff space)
- How do different modes (simple/deep) relate to patterns? (Composition)

**For future sessions:**
- Error handling (timeouts, low confidence across the board, contradictory sources)
- Iteration ("dig deeper on point 3" — fresh delegation or build on previous?)

## Artifacts

- Reddit diagram showing Simple (iterative) vs Deep (parallel+hierarchical) modes

## Next Steps

1. Complete M4 design: Error handling (C) and Iteration (D)
2. Build M4: Implement delegation from Limen to research agent
3. Then: M5 (Quality evaluation — self-critique, confidence scores)

## Meta-Observations

**What worked well:**
- Going concept by concept, not rushing
- Retention checks before new material
- Connecting new concepts back to prior ones (ReAct, metacognition)
- Kartik asking for real-world validation ("is this how systems actually do it?")
- Using external diagram to validate understanding

**Kartik's learning pattern:**
- Wants comprehensive coverage, not shortcuts
- Connects concepts to practical implementation
- Asks "why" and "how does this compare to production"
- Good at identifying when concepts are actually the same thing (delegation vs orchestration nuance)
